ğŸ¦ Credit Risk Classification Engine with Explainability & Fairness Audits
ğŸ” Project Summary
This project builds a full-stack, explainable AI pipeline to assess credit risk using real-world-like features from the UCI Credit Approval dataset. It includes:

Binary classification (Approve/Deny) via XGBoost

SHAP-based interpretability

Risk bucketing + business rule overrides

Fairness auditing & disparate impact analysis

Anomaly detection + temporal features

Cluster-based risk insights & cost-sensitive retraining

ğŸš€ Key Features
Feature	Description
ğŸ§  Models	Logistic Regression, Random Forest, XGBoost
ğŸ“ˆ Performance	Accuracy: 90.6% Â· F1: 89.1% Â· ROC AUC: 94.6%
ğŸª„ Explainability	SHAP beeswarm + waterfall plots + top-3 feature logging
âš–ï¸ Fairness	Disparate impact check by demographic proxy (A1)
ğŸ“Š Risk Logic	Probability â†’ Risk Bucket â†’ Override (business logic)
ğŸ•µï¸â€â™‚ï¸ Anomaly Detection	Isolation Forest on feature signals
ğŸ•° Temporal Intelligence	Time since last high-risk, rolling 24h approval avg
ğŸ§ª Custom Features	Credit utilization, new customer flag, missed payment flag
ğŸ§  Clustering	KMeans clusters for behavioral grouping
ğŸ’¸ Cost-Sensitive Modeling	XGBoost tuned with scale_pos_weight to balance approvals

ğŸ“ File Structure
r
Copy
Edit
ğŸ“¦ credit-risk-model/
â”‚
â”œâ”€â”€ Credit_risk.ipynb         <- Main notebook (Jupyter pipeline)
â”œâ”€â”€ crx.data                  <- Raw UCI dataset
â”œâ”€â”€ crx.names                 <- Dataset metadata
â”œâ”€â”€ credit.lisp / credit.names / Index  <- Dataset docs
â”œâ”€â”€ Credit_risk.pdf           <- Exported notebook for offline viewing
â”œâ”€â”€ README.md                 <- You're here :)
ğŸ› ï¸ Tech Stack
Language: Python 3.10+

ML Models: XGBoost, Random Forest, Logistic Regression

Explainability: SHAP

Visualization: Matplotlib, Seaborn

Preprocessing: scikit-learn (LabelEncoder, StandardScaler, SimpleImputer)

Extras: KMeans, IsolationForest, StratifiedKFold, datetime

ğŸ§ª Example Outputs
ğŸ“Š SHAP Beeswarm

ğŸ’§ SHAP Waterfall (Sample Prediction)

ğŸ“‹ Classification Report
yaml
Copy
Edit
Accuracy: 0.906
Precision: 0.91
Recall: 0.87
F1 Score: 0.89
ğŸ“ˆ Business Rules Logic
python
Copy
Edit
if approval_prob >= 0.6:
    decision = "Approve"
else:
    decision = "Manual Review"

# Override for high risk
if risk_bucket == "High Risk":
    final_decision = "Deny"
ğŸ“‰ Fairness Evaluation
Disparate impact was measured on the A1 feature:

python
Copy
Edit
Disparate Impact (A1): 0.028
A low disparity suggests minimal bias between demographic groups.

ğŸ§  Future Improvements
Streamlit UI for credit officer decision-support

Deployment via Docker + REST API

Integration with vector DB for audit trail storage

LLM summarizer for SHAP explanations

ğŸ‘¤ Author
Anirudh Reddy Ninganpally
GitHub Portfolio
ğŸ’¼ Open to Data Analyst / ML Engineer roles

ğŸ“œ License
This project is released under the MIT License.